{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f390b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6d9795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce GTX 1650 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea42244",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(\"features.npy\")\n",
    "labels = np.load(\"labels.npy\")\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    features, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# convert to torch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_val   = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)\n",
    "X_test  = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val   = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "val_ds   = TensorDataset(X_val, y_val)\n",
    "test_ds  = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4606d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM_Model_PyTorch(nn.Module):\n",
    "    def __init__(self, num_classes=24):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # After 3 MaxPool2d(2), height & width are divided by 8\n",
    "        self.lstm_input_size = 128 * ((150//8))  # height collapsed into features\n",
    "        self.lstm = nn.LSTM(self.lstm_input_size, 128, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(128*2, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.cnn(x)  # (B, C, H, W)\n",
    "\n",
    "        # Reshape to (B, time_steps, features)\n",
    "        x = x.permute(0, 3, 1, 2)  # (B, W, C, H)\n",
    "        x = x.contiguous().view(batch_size, x.size(1), -1)  # (B, W, C*H)\n",
    "\n",
    "        lstm_out, (h_n, _) = self.lstm(x)\n",
    "        h = torch.cat((h_n[-2], h_n[-1]), dim=1)  # (B, 256)\n",
    "\n",
    "        h = self.dropout1(h)\n",
    "        h = torch.relu(self.fc1(h))\n",
    "        h = self.dropout2(h)\n",
    "        out = self.out(h)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b43b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_LSTM_Model_PyTorch().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1551a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] | Train Loss: 3.0506 Acc: 0.0923 | Val Loss: 2.8517 Acc: 0.1909\n",
      "Epoch [2/15] | Train Loss: 2.4667 Acc: 0.2626 | Val Loss: 1.9294 Acc: 0.4635\n",
      "Epoch [3/15] | Train Loss: 1.7694 Acc: 0.4436 | Val Loss: 1.3661 Acc: 0.6463\n",
      "Epoch [4/15] | Train Loss: 1.3537 Acc: 0.5790 | Val Loss: 1.0193 Acc: 0.7649\n",
      "Epoch [5/15] | Train Loss: 1.0506 Acc: 0.6777 | Val Loss: 0.7567 Acc: 0.8433\n",
      "Epoch [6/15] | Train Loss: 0.8324 Acc: 0.7554 | Val Loss: 0.5838 Acc: 0.8855\n",
      "Epoch [7/15] | Train Loss: 0.6654 Acc: 0.8107 | Val Loss: 0.4353 Acc: 0.9183\n",
      "Epoch [8/15] | Train Loss: 0.5242 Acc: 0.8611 | Val Loss: 0.3357 Acc: 0.9457\n",
      "Epoch [9/15] | Train Loss: 0.4242 Acc: 0.8936 | Val Loss: 0.2622 Acc: 0.9585\n",
      "Epoch [10/15] | Train Loss: 0.3371 Acc: 0.9235 | Val Loss: 0.2073 Acc: 0.9699\n",
      "Epoch [11/15] | Train Loss: 0.2822 Acc: 0.9386 | Val Loss: 0.1613 Acc: 0.9719\n",
      "Epoch [12/15] | Train Loss: 0.2286 Acc: 0.9545 | Val Loss: 0.1405 Acc: 0.9739\n",
      "Epoch [13/15] | Train Loss: 0.1932 Acc: 0.9610 | Val Loss: 0.1108 Acc: 0.9812\n",
      "Epoch [14/15] | Train Loss: 0.1624 Acc: 0.9688 | Val Loss: 0.1056 Acc: 0.9839\n",
      "Epoch [15/15] | Train Loss: 0.1408 Acc: 0.9720 | Val Loss: 0.0857 Acc: 0.9846\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir='./logs')\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(15):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0.0, 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "        train_correct += (preds == y_batch).sum().item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = train_correct / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            val_correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc = val_correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/15] | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Val\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Train\", train_acc, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Val\", val_acc, epoch)\n",
    "\n",
    "    # checkpoint\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff71c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_420/685210218.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test Accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        output = model(X_batch)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        test_correct += (preds == y_batch).sum().item()\n",
    "\n",
    "test_acc = test_correct / len(test_loader.dataset)\n",
    "print(f\"âœ… Test Accuracy: {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
